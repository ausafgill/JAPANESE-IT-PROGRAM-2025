{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuzCJiLyYP3a"
      },
      "source": [
        "---\n",
        "\n",
        "# **IT Training Assignment Class 4**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JH8b39wbr14H"
      },
      "source": [
        "### **Import Required Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "g0sCx7hpr1om"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38w50UUE_9RZ"
      },
      "source": [
        "### **Task 01: 1D & 2D Array Operations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "Z5yh8FUBr0iH"
      },
      "outputs": [],
      "source": [
        "# Create a 1D and 2D array (Global Variables)\n",
        "array_1d = np.array([1, 2, 3, 4, 5])\n",
        "array_2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlBfsJdssOZa",
        "outputId": "8cc8fa61-58ff-44c0-f2f0-55101f137e01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1D Array:\n",
            " [1 2 3 4 5]\n",
            "2D Array:\n",
            " [[1 2 3]\n",
            " [4 5 6]\n",
            " [7 8 9]]\n"
          ]
        }
      ],
      "source": [
        "# Output the arrays\n",
        "print(\"1D Array:\\n\", array_1d)\n",
        "print(\"2D Array:\\n\", array_2d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "gKcbTldase1s"
      },
      "outputs": [],
      "source": [
        "# Implement a function for Basic array Operations\n",
        "def basic_array_operations():\n",
        "  # 1D array operations\n",
        "  print(\"Sum of 1D Array:\", np.sum(array_1d))\n",
        "\n",
        "  # 2D array operations\n",
        "  print(\"Mean of a 2D Array::\", np.mean(array_2d))\n",
        "  print(\"Transpose of 2D Array:\\n\",array_2d.T)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sr8WVucBs6g1",
        "outputId": "f4e56fbd-4596-4e36-c947-28aef0da884c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sum of 1D Array: 15\n",
            "Mean of a 2D Array:: 5.0\n",
            "Transpose of 2D Array:\n",
            " [[1 4 7]\n",
            " [2 5 8]\n",
            " [3 6 9]]\n"
          ]
        }
      ],
      "source": [
        "# Create global array variables\n",
        "global arr_1d;\n",
        "global arr_2d;\n",
        "\n",
        "arr_1d = np.array([1, 2, 3, 4, 5])\n",
        "arr_2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "\n",
        "# Call basic array operations function\n",
        "basic_array_operations()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mipxUFbxuxTO"
      },
      "source": [
        "### **Task 02: Image Processing with NumPy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "xfZQQoJYuUrx"
      },
      "outputs": [],
      "source": [
        "# Implement a function to create and crop the image using local variables\n",
        "def image_processing():\n",
        "  # Create a grayscale image using 2d numpy array\n",
        "  image = np.random.randint(0, 256, (5, 5), dtype=np.uint8)\n",
        "\n",
        "  # Print original Image\n",
        "  print(\"Original Image:\\n\", image)\n",
        "\n",
        "  # Crop the image\n",
        "  cropped = image[1:4, 1:4]\n",
        "  # Invert colors\n",
        "  inverted_image = 255 - image\n",
        "\n",
        "  # Print cropped section of image\n",
        "  print(\"Cropped Section:\\n\", cropped)\n",
        "  # Print inverted image\n",
        "  print(\"Inverted Image:\\n\", inverted_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRdp1sSeXjC5",
        "outputId": "80afc296-298b-4a49-edb9-a6e15d6e498a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Image:\n",
            " [[254  76  29  74  29]\n",
            " [ 16 232 183   6 118]\n",
            " [133 156  20  51  68]\n",
            " [144 137  46   1 105]\n",
            " [ 72  84 179  33  73]]\n",
            "Cropped Section:\n",
            " [[232 183   6]\n",
            " [156  20  51]\n",
            " [137  46   1]]\n",
            "Inverted Image:\n",
            " [[  1 179 226 181 226]\n",
            " [239  23  72 249 137]\n",
            " [122  99 235 204 187]\n",
            " [111 118 209 254 150]\n",
            " [183 171  76 222 182]]\n"
          ]
        }
      ],
      "source": [
        "# Call the image processing function to print output\n",
        "image_processing()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BzQ0YRyYszV"
      },
      "source": [
        "### **Task 03: Augmented Reality Transformation: Perform linear algebra operations like scaling, rotation, and translation.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "vKElqDfXYdQQ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:1: SyntaxWarning: invalid escape sequence '\\J'\n",
            "<>:1: SyntaxWarning: invalid escape sequence '\\J'\n",
            "C:\\Users\\Ausaf\\AppData\\Local\\Temp\\ipykernel_12380\\1667624457.py:1: SyntaxWarning: invalid escape sequence '\\J'\n",
            "  image_path = \"D:\\JAPANESE-IT-PROGRAM\\Class 4\\my_image.jpg\"  # Adjust this\n"
          ]
        }
      ],
      "source": [
        "image_path = \"D:\\JAPANESE-IT-PROGRAM\\Class 4\\my_image.jpg\"  # Adjust this\n",
        "image = cv2.imread(image_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "U_STBUVpZck0"
      },
      "outputs": [],
      "source": [
        "# Implement a function to scale image by a scale factor\n",
        "def scale_image(image, scale_factor):\n",
        "  # Create a scale matrix from scale factor\n",
        "\n",
        "  scaling_matrix = np.array([[scale_factor, 0, 0],\n",
        "                             [0, scale_factor, 0],\n",
        "                             [0, 0, 1]])\n",
        "  # Get image dimensions\n",
        "  rows, cols = image.shape[:2]\n",
        "\n",
        "  # Apply transformation and return scaled image\n",
        "  scaled_image = cv2.warpPerspective(image, scaling_matrix, (cols, rows))\n",
        "  return scaled_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "qCX_DocfaHio"
      },
      "outputs": [],
      "source": [
        "# Implement a function to rotate and image by a given angle\n",
        "def rotate_image(image, angle):\n",
        "  # Get image dimensions\n",
        "  rows, cols = image.shape[:2]\n",
        "\n",
        "  # Calculate rotation matrix\n",
        "  rotation_matrix = cv2.getRotationMatrix2D((cols/2, rows/2), angle, 1)\n",
        "\n",
        "  # Apply rotation and return the rotated image\n",
        "  rotated_image = cv2.warpAffine(image, rotation_matrix, (cols, rows))\n",
        "  return rotated_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "g3jBvLJOab3H"
      },
      "outputs": [],
      "source": [
        "# Implement a function to translate an image to x, y axis\n",
        "def translate_image(image, tx, ty):\n",
        "  # Create translation matrix\n",
        "  translation_matrix = np.array([[1, 0, tx],\n",
        "                                 [0, 1, ty]], dtype=np.float32)\n",
        "  # Get image dimensions\n",
        "  rows, cols = image.shape[:2]\n",
        "\n",
        "  # Apply transformation\n",
        "  translated_image = cv2.warpAffine(image, translation_matrix, (cols, rows))\n",
        "  return translated_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PHee3g8Dazyd",
        "outputId": "6c2b46f2-c9f9-479c-9ca2-4597250831fc"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Error: Unable to load the image. Check the file path!",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[89], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour_image.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: Unable to load the image. Check the file path!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Apply transformations\u001b[39;00m\n\u001b[0;32m     10\u001b[0m scaled_image \u001b[38;5;241m=\u001b[39m scale_image(image, \u001b[38;5;241m1.5\u001b[39m)\n",
            "\u001b[1;31mValueError\u001b[0m: Error: Unable to load the image. Check the file path!"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "\n",
        "# Load the image\n",
        "image = cv2.imread(\"your_image.jpg\")\n",
        "\n",
        "if image is None:\n",
        "    raise ValueError(\"Error: Unable to load the image. Check the file path!\")\n",
        "\n",
        "# Apply transformations\n",
        "scaled_image = scale_image(image, 1.5)\n",
        "rotated_image = rotate_image(image, 45)\n",
        "translated_image = translate_image(image, 50, 30)\n",
        "\n",
        "# Display images\n",
        "cv2.imshow(\"Original Image\", image)\n",
        "cv2.imshow(\"Scaled Image\", scaled_image)\n",
        "cv2.imshow(\"Rotated Image\", rotated_image)\n",
        "cv2.imshow(\"Translated Image\", translated_image)\n",
        "\n",
        "# Wait for key press and close windows\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znoXJa_odjER"
      },
      "source": [
        "### **Task 04: Face Detection from Image Arrays – Extract facial features by slicing a NumPy-based image array.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3qxGLvZd_2J"
      },
      "outputs": [],
      "source": [
        "# Preprocess Image to grayscale\n",
        "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebm145qndkYr"
      },
      "outputs": [],
      "source": [
        "# Load OpenCV's pretrained Haar Cascade for face detection\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q58irJetd2BN"
      },
      "outputs": [],
      "source": [
        "# Detect face in image\n",
        "faces = face_cascade.detectMultiScale(image_gray, scaleFactor=1.1, minNeighbors=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "dd0W0EQ_eJ1f",
        "outputId": "4ce9f6cc-e323-44dd-efc1-bcc5bc734e29"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'faces' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[30], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Loop through detected faces and extracted facial features\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (x, y, w, h) \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfaces\u001b[49m:\n\u001b[0;32m      3\u001b[0m   \u001b[38;5;66;03m# Extract facial features\u001b[39;00m\n\u001b[0;32m      4\u001b[0m   face_roi \u001b[38;5;241m=\u001b[39m image_gray[y:y\u001b[38;5;241m+\u001b[39mh, x:x\u001b[38;5;241m+\u001b[39mw]\n\u001b[0;32m      6\u001b[0m   \u001b[38;5;66;03m# Display face region\u001b[39;00m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'faces' is not defined"
          ]
        }
      ],
      "source": [
        "# Loop through detected faces and extracted facial features\n",
        "for (x, y, w, h) in faces:\n",
        "  # Extract facial features\n",
        "  face_roi = image_gray[y:y+h, x:x+w]\n",
        "\n",
        "  # Display face region\n",
        "  cv2_imshow(face_roi)\n",
        "\n",
        "  # Extract additional features\n",
        "  eyes_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
        "  eyes = eyes_cascade.detectMultiScale(face_roi, scaleFactor=1.1, minNeighbors=5)\n",
        "\n",
        "  # Display eye regions\n",
        "  for (ex, ey, ew, eh) in eyes:\n",
        "    eye_roi = face_roi[ey:ey+eh, ex:ex+ew]\n",
        "    cv2_imshow(eye_roi)\n",
        "\n",
        "# Show original image with detected face\n",
        "print(\"Detected Face\")\n",
        "cv2_imshow(image)\n",
        "\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYukM28vfG1C"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
